<h1 align="center">Model Evaluation (i) </h1>

The program evaluation_01.ipynb in this folder fine-tunes and evaluates BertForSequenceClassification which 
is a pretrained model from the BERT-model-family made available via Hugingface's transformer library. 
Built on top of the base BERT model, BertForSequenceClassification adds a classification head on top of the 
BERT encoder. Here, BertForSequenceClassification trained and evaluated against a binary classification task of 0/1 movie assessments.
A simple set of labeled data (text_classification_data.csv) is split into training and testing set used accordingly by the program. 
Accuracy is used as an evaluation metric. The data is available here and can be easily be edited or extended. For a meaningful evaluation the dataset is too small. Its purpose  is to illustrate how a pretrained LLM can be evaluated. Next is breakdown of the what evaluation_01.ipynb does:

* Installation and Uninstallation of Dependencies:
  + The program installs necessary libraries (transformers, datasets, and evaluate).
  + It downgrades pyarrow and reinstalls cudf-cu12 and ibis-framework.

* Loading Pre-trained Model and Tokenizer:
  + Loads the bert-base-uncased model from the Hugging Face Transformers library.
  + Loads the corresponding tokenizer.

* Loading and Preparing the Dataset:
  + Reads a CSV file containing text and labels for classification.
  + Converts the pandas DataFrame to a Hugging Face Dataset.

* Preprocessing the Dataset
  + Applies tokenization and padding/truncation to the text data to prepare it for the model.

* Defining the Evaluation Metric
  + Uses the evaluate library to load the accuracy metric, which will be used to evaluate the modelâ€™s performance.

* Setting Up Training Arguments
  + Defines training parameters such as the output directory, number of epochs, batch sizes, and evaluation strategy.

* Splitting the Dataset
  + Splits the dataset into training and testing sets (80-20 split).

* Training the Model:
  + Uses the Trainer class from the Transformers library to handle the training loop, evaluation, and logging.
  + Trains the model for the specified number of epochs which is set to 3.  

* Evaluating the Model
  + Evaluates the trained model on the test set and prints the evaluation results.




### Diagram for embeddings_01.ipynb

```mermaid
graph TD
    A[Start] --> B[Install Dependencies]
    B --> C[Load Pre-trained Model and Tokenizer]
    C --> D[Load Custom Dataset]
    D --> E[Convert DataFrame to HuggingFace Dataset]
    E --> F[Preprocess Dataset]
    F --> G[Define Evaluation Metric]
    G --> H[Setup Training Arguments]
    H --> I[Split Dataset]
    I --> J[Create Trainer]
    J --> K[Train Model]
    K --> L[Evaluate Model]
    L --> M[Print Evaluation Results]
    M --> N[End]
```




### Evaluation
The evaluation results are shown in the Figure below. 
Not unexpectedly, there is a perfect accuracy (1.0) suggesting that the model might be overfitting to the training data which is a likely consequence of the small evaluation set used. 



<p align="center">
  <img src="./evaluation_result_01.png" alt="Output generated by evaluation_01.png" "Output generated by evaluation_01.png"/>
</p>


