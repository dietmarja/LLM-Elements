{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUo1BpBOQ5wJoDXOQezBon"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Training Loop Example\n","\n","\n"],"metadata":{"id":"Talb1zgLGaRg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AljZMTyFF8_A"},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel"]},{"cell_type":"code","source":["# Initialize the model and tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"],"metadata":{"id":"WspWdV6rGeQj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add a padding token if it doesn't exist\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token})\n","    model.resize_token_embeddings(len(tokenizer))"],"metadata":{"id":"1tGqmSHpHwer"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare the data (we use a simply dummy dataset)\n","texts = [\"Example sentence one.\", \"Example sentence two.\"]\n","inputs = tokenizer(\n","    texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128\n",")\n"],"metadata":{"id":"jXbbG-oOH0yd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the optimizer and loss function\n","optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n","loss_fn = nn.CrossEntropyLoss()\n"],"metadata":{"id":"HCqjFU5OH9zS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","epochs = 3\n","for epoch in range(epochs):\n","    model.train()\n","    for i in range(len(inputs[\"input_ids\"])):\n","        input_ids = inputs[\"input_ids\"][i].unsqueeze(0)\n","        attention_mask = inputs[\"attention_mask\"][i].unsqueeze(0)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n","        loss = outputs.loss\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 10 == 0:  # Print loss every 10 batches\n","            print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n","\n","    # Evaluation (optional, usually done on a validation set)\n","    with torch.no_grad():\n","        # Evaluation code here (e.g., compute validation loss)\n","        pass\n","\n","print(\"Training completed.\")\n","\n","\n","# Output\n","# Epoch: 0, Batch: 0, Loss: 7.130513668060303\n","# Epoch: 1, Batch: 0, Loss: 3.1593968868255615\n","# Epoch: 2, Batch: 0, Loss: 1.7124954462051392\n","# Training completed."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZ8GexDoIDu-","executionInfo":{"status":"ok","timestamp":1717502518574,"user_tz":-60,"elapsed":12414,"user":{"displayName":"Dietmar Janetzko","userId":"09263428992827345400"}},"outputId":"7ae59258-f5c8-487c-be1d-e76d8cf4e15f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Batch: 0, Loss: 7.130513668060303\n","Epoch: 1, Batch: 0, Loss: 3.1593968868255615\n","Epoch: 2, Batch: 0, Loss: 1.7124954462051392\n","Training completed.\n"]}]}]}