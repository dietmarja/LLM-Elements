{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeevTbG2cMNaWDKhKq5RzY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dietmarja/LLM-Elements/blob/main/vector_db/pinecone_02a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run setup_colab.py\n"
      ],
      "metadata": {
        "id": "8pj4L7TAebdu"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run setup_pinecone.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjIJya-ckfV2",
        "outputId": "dcc3c8c6-e4f0-4ce1-fe42-a00aa98449fc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing index deleted\n",
            "Index created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qU install transformers pinecone-client torch langchain PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q5rYDH6nN2wt",
        "outputId": "0c87a00a-95ce-49d4-c28e-9d8d1f159e2f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (4.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.5-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.6.2)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.7)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.77)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Collecting PyMuPDFb==1.24.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
            "Installing collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.5 PyMuPDFb-1.24.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "from langchain import LLMChain\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import pinecone\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "KCNrOrsjbfWF"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Pinecone\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "\n",
        "\n",
        "# Create a pincecone client\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Create a pincecone client\n",
        "index_name = \"docs-quickstart-index\"\n",
        "\n",
        "# Check if the index exists and delete it if it does\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)\n",
        "    print(\"Existing index deleted\")\n",
        "\n",
        "# Create the index\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=384,\n",
        "    metric=\"cosine\",  # Available metrics: \"euclidean\"/\"manhattan\"/\"dotproduct\"/\"cosine\"\n",
        "    spec=ServerlessSpec(\n",
        "        cloud='aws',\n",
        "        region='us-east-1'\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Index created successfully\")\n",
        "\n",
        "# Connect pc to the index\n",
        "index = pc.Index(index_name)\n",
        "print(\"Connected to the index\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTgbyy0thHno",
        "outputId": "05234a21-7f89-4f39-9a26-d63f0caf80bf"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing index deleted\n",
            "Index created successfully\n",
            "Connected to the index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a Hugging Face model and tokenizer\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define a simple embedding function using Hugging Face model\n",
        "def embed_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
        "    return embeddings.detach().numpy()\n"
      ],
      "metadata": {
        "id": "X1Js0bANofUQ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -qU transformers pinecone-client torch langchain"
      ],
      "metadata": {
        "id": "48xdPP-6rq1B"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import pinecone\n",
        "import torch\n",
        "\n",
        "# Load a Hugging Face model and tokenizer\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Define a simple embedding function using Hugging Face model\n",
        "def embed_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).last_hidden_state.mean(dim=1).squeeze().tolist()\n",
        "        # Ensure the embedding is a flat list of floats\n",
        "        if isinstance(embeddings[0], list):\n",
        "            embeddings = [item for sublist in embeddings for item in sublist]\n",
        "    if len(embeddings) != 384:\n",
        "        raise ValueError(f\"Embedding dimension mismatch: Expected 384, got {len(embeddings)}\")\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "id": "B4mdYImGPT3a"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DvgpfPPSbccF",
        "outputId": "379c3461-4c12-4b79-e7df-7c47166546e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query embedding 1: [-0.14562642574310303, 0.5601049661636353, 0.5747165679931641, 0.5388968586921692, 0.0780593603849411, 0.31727224588394165, -0.12419245392084122, 0.6555048227310181, 0.35049957036972046, 0.0017658972647041082, 0.09825917333364487, 0.16016599535942078, 0.6524692177772522, -0.4563508629798889, -0.5212566256523132, -0.10932393372058868, -0.3860594928264618, 0.05149644613265991, 0.14169219136238098, 0.2924876809120178, 0.17130199074745178, 0.7985489964485168, 0.09196789562702179, -0.3987356722354889, -0.02856002189218998, -0.07411689311265945, -0.5267559885978699, -0.9285850524902344, -0.12639212608337402, 0.013689696788787842, -0.07382040470838547, 0.178280308842659, 0.2382897287607193, 0.6428471803665161, 0.43961596488952637, -0.3523942530155182, 0.07005397230386734, -0.3105872571468353, 0.3699536919593811, 0.2713792026042938, -0.2558605968952179, -0.26600202918052673, 0.09510897099971771, -0.3179085850715637, 0.18635237216949463, -0.09240924566984177, -0.5089095830917358, 0.4687177240848541, 0.5297709703445435, 0.3627423346042633, -1.009641408920288, -0.23459136486053467, -0.386486679315567, 0.11969473212957382, 0.607792854309082, 0.20298469066619873, -0.6103916168212891, 0.5177938342094421, -0.5403170585632324, -0.4653698801994324, 0.29509738087654114, -0.31185632944107056, -0.09715750068426132, 0.028102559968829155, 0.03138355165719986, -0.23720690608024597, 0.21934805810451508, -0.2522215247154236, 0.527974545955658, -0.38561078906059265, -0.20120862126350403, -0.04553455859422684, 0.33721765875816345, -0.2808862030506134, 0.13005831837654114, 0.5400864481925964, -0.11177326738834381, 0.0892597958445549, 0.15813899040222168, -0.18965645134449005, -0.14273647964000702, -0.2833227813243866, -0.4908466935157776, -0.11197469383478165, -0.42062482237815857, -0.3201499581336975, 0.46641165018081665, -0.6078519225120544, 0.5926996469497681, -0.42340153455734253, 0.15076442062854767, -0.5690242648124695, -0.10000820457935333, -0.20459501445293427, -0.34530046582221985, 0.13562123477458954, 0.24287065863609314, 0.04096152260899544, 0.8720871806144714, 0.03637392073869705, -0.09667231142520905, 0.24839255213737488, 0.3177323639392853, -0.31729409098625183, -0.41577625274658203, 0.4363855719566345, -0.5651540160179138, -0.15823128819465637, -0.1401544064283371, -0.5190972089767456, -0.38521531224250793, -0.2676430940628052, -0.2991872727870941, -0.5375162959098816, -0.08281994611024857, 0.22634664177894592, 0.36848530173301697, -0.2696632444858551, -0.03501059487462044, 0.11619500070810318, -0.08686085790395737, 0.25150421261787415, -0.1320541501045227, -0.43655699491500854, -0.3900291919708252, 0.08986148983240128, 0.036732036620378494, -2.4806842994486597e-33, 0.3904387652873993, -0.2070881426334381, -0.26821935176849365, -0.03395404294133186, -0.27645426988601685, 0.2274559587240219, 0.6522647142410278, 0.5149189233779907, -0.513037383556366, -0.3175114095211029, -0.46226805448532104, 0.2633708715438843, -0.29704514145851135, -0.4136326313018799, -0.24568317830562592, 0.03342133015394211, -0.12097484618425369, -0.14990054070949554, -0.42813840508461, 0.024490628391504288, 0.03582808002829552, -0.2390149086713791, 0.1359068900346756, 0.11544756591320038, 0.24314670264720917, -0.1688161939382553, -0.12118596583604813, -0.8805121183395386, -0.11938098818063736, -0.07180921733379364, -0.42766597867012024, -0.09002746641635895, -0.7974579930305481, -0.5233614444732666, -0.1508316844701767, 0.5491952896118164, -0.240144282579422, 0.359554260969162, 0.007905183359980583, 0.2776434123516083, -0.8492859601974487, 0.20080147683620453, 0.8652543425559998, -0.7452033162117004, 0.10184697806835175, -0.3948298394680023, -0.4783511757850647, -0.18109223246574402, 0.06712909042835236, -0.05095716938376427, -0.00405645789578557, 0.39965686202049255, -0.542249858379364, 0.08476454764604568, 0.9168270230293274, 0.04854026809334755, 0.16039177775382996, 1.0704736709594727, 0.06759624928236008, 0.16454783082008362, 0.39422765374183655, -0.3915106952190399, 0.33530542254447937, -0.2863444983959198, -0.23076775670051575, -0.362969309091568, 0.06317684054374695, 0.6404868960380554, 0.23851369321346283, 0.5897364616394043, 0.5837358832359314, 0.14610841870307922, 0.21536217629909515, -0.21631188690662384, 0.6164331436157227, -0.15914753079414368, 0.1943667232990265, -0.4307050108909607, -0.3640737533569336, -0.0767052173614502, -0.4306679368019104, -0.35144931077957153, -0.0885077640414238, 0.6057339906692505, -0.17780523002147675, 0.28512582182884216, 0.35865309834480286, 0.09278862178325653, 0.05551815405488014, -0.43993085622787476, 0.3842160701751709, 0.4654760956764221, -0.3995734751224518, -0.3047153651714325, 0.2942495346069336, -1.7534579234857358e-33, 0.13266406953334808, -0.9734318852424622, 0.08929301798343658, -0.13607783615589142, -0.1851045787334442, 0.009903425350785255, 0.1398719996213913, -0.11941100656986237, 0.04721301421523094, 0.49232056736946106, 0.6012440323829651, -0.02038869634270668, -0.05386442318558693, -0.3858906626701355, -0.15387305617332458, 0.30214163661003113, -0.06000256910920143, -0.14908811450004578, -0.17645737528800964, 0.7560387253761292, -0.22436213493347168, 0.10661392658948898, -0.5473673939704895, 0.44828101992607117, 0.008104746229946613, -0.1642628014087677, 0.06691562384366989, -0.02952580340206623, -0.41438034176826477, 0.07064343243837357, -0.06368517130613327, -0.1481078416109085, -0.49519774317741394, 0.7595795392990112, -0.10297542810440063, -0.026946986094117165, -0.2345503270626068, 0.3568957448005676, 0.0618542842566967, 0.12671877443790436, 0.37346139550209045, 0.10609868913888931, 0.18653400242328644, 0.3523156940937042, -0.24293027818202972, -0.28437724709510803, 0.11810185015201569, 0.3039781153202057, 0.4063873887062073, 0.16902874410152435, 0.32890674471855164, 0.1501612514257431, 0.2368287593126297, -0.3301698565483093, -0.04719514399766922, -0.3570016920566559, -0.3575216233730316, -0.15556184947490692, -0.3891369700431824, 0.37807697057724, 0.22585681080818176, 1.0488624572753906, -0.1716800034046173, 0.5829349756240845, -0.15462779998779297, -0.29547119140625, -0.6307198405265808, 0.26220041513442993, -0.5891333818435669, 0.2719660699367523, 0.10068442672491074, -0.31235724687576294, 0.465139776468277, -0.11546063423156738, 0.49312087893486023, 0.602357029914856, -0.1556522101163864, 0.10612467676401138, -0.13697656989097595, -0.18950138986110687, 0.28815001249313354, 0.4523690342903137, 0.10914885997772217, 0.27097466588020325, -0.12621141970157623, 0.20268858969211578, 0.2922191321849823, 0.32688453793525696, -0.625712513923645, -0.18916413187980652, -0.08702922612428665, -0.22164872288703918, -0.3845573365688324, -0.2116091549396515, 0.3385811150074005, -9.439579429226796e-08, -0.40054580569267273, 0.19141200184822083, -0.09233122318983078, 0.1734871119260788, 0.40052083134651184, 0.45835965871810913, -0.12107395380735397, 0.9270672798156738, -0.4959048628807068, -0.1570492535829544, 0.15546448528766632, -0.1073320284485817, -0.04248277097940445, -0.14451704919338226, 0.10373610258102417, -0.049658287316560745, 0.08291490375995636, -0.3328233063220978, -0.26150503754615784, -0.11215822398662567, -0.0025041443295776844, 0.09910617768764496, 0.13657084107398987, -0.17263516783714294, 0.2297130823135376, 0.5475944876670837, -0.3380160927772522, 0.26904916763305664, 0.49463894963264465, -0.11689966171979904, 0.0093699861317873, 0.28066739439964294, -0.5529201030731201, 0.023183418437838554, 0.8776505589485168, -0.14251075685024261, 0.2585316002368927, 0.0615333653986454, -0.9130857586860657, 0.03380129113793373, 0.6015145182609558, 0.24955947697162628, -0.26164382696151733, -0.00733027933165431, -0.0034187522251158953, -0.01453238446265459, 0.6608959436416626, -0.532291054725647, 0.4032561182975769, -0.3271964490413666, -0.14686861634254456, -0.3837737441062927, 0.7337098717689514, -0.3870101273059845, -0.6908324360847473, 0.31214332580566406, 0.4716128408908844, 0.33772653341293335, 0.020741034299135208, -0.4733656048774719, -0.1260528862476349, 0.26890233159065247, 0.30950894951820374, 0.6731187105178833]\n",
            "Query embedding 1 dimension: 384\n",
            "Results for document 1:\n",
            "{'matches': [], 'namespace': '', 'usage': {'read_units': 1}}\n"
          ]
        }
      ],
      "source": [
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Function to store document in Pinecone\n",
        "def store_document(doc_id, text):\n",
        "    embedding = embed_text(text)\n",
        "    index.upsert(vectors=[(doc_id, embedding)])\n",
        "\n",
        "# Path to PDF file\n",
        "pdf_path_1 = \"Attention_Paper.pdf\"\n",
        "#pdf_path_2 = \"path/to/your/document2.pdf\"\n",
        "\n",
        "# Extract text from PDFs\n",
        "text_1 = extract_text_from_pdf(pdf_path_1)\n",
        "#text_2 = extract_text_from_pdf(pdf_path_2)\n",
        "\n",
        "# Store extracted text in Pinecone\n",
        "store_document(\"doc_1\", text_1)\n",
        "#store_document(\"doc_2\", text_2)\n",
        "\n",
        "# Query Pinecone for multiple documents\n",
        "query_embedding_1 = embed_text(\"search query for doc 1\")\n",
        "#query_embedding_2 = embed_text(\"search query for doc 2\")\n",
        "\n",
        "# Show the query embedding\n",
        "print(f\"Query embedding 1: {query_embedding_1}\")\n",
        "print(f\"Query embedding 1 dimension: {len(query_embedding_1)}\")\n",
        "#print(f\"Query embedding 2: {query_embedding_2}\")\n",
        "#print(f\"Query embedding 2 dimension: {len(query_embedding_2)}\")\n",
        "\n",
        "results_1 = index.query(vector=query_embedding_1, top_k=10)\n",
        "#results_2 = index.query(vector=query_embedding_2, top_k=10)\n",
        "\n",
        "print(\"Results for document 1:\")\n",
        "print(results_1)\n",
        "\n",
        "#print(\"\\nResults for document 2:\")\n",
        "#print(results_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import pinecone\n",
        "import torch\n",
        "\n",
        "# Load a Hugging Face model and tokenizer\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define a simple embedding function using Hugging Face model\n",
        "def embed_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).last_hidden_state.mean(dim=1).squeeze().tolist()\n",
        "        # Ensure the embedding is a flat list of floats\n",
        "        if isinstance(embeddings[0], list):\n",
        "            embeddings = [item for sublist in embeddings for item in sublist]\n",
        "    if len(embeddings) != 384:\n",
        "        raise ValueError(f\"Embedding dimension mismatch: Expected 384, got {len(embeddings)}\")\n",
        "    return embeddings\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    texts = []\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page_num, page in enumerate(doc):\n",
        "            text = page.get_text()\n",
        "            texts.append((page_num, text))\n",
        "    return texts\n",
        "\n",
        "# Function to store document in Pinecone\n",
        "def store_document(doc_id, text):\n",
        "    embedding = embed_text(text)\n",
        "    index.upsert(vectors=[(doc_id, embedding)])\n",
        "\n",
        "# Path to your PDF file\n",
        "pdf_path_1 = \"Attention_Paper.pdf\"\n",
        "pdf_path_2 = \"Lora_Paper.pdf\"\n",
        "\n",
        "# Extract text from PDF\n",
        "texts_1 = extract_text_from_pdf(pdf_path_1)\n",
        "texts_2 = extract_text_from_pdf(pdf_path_2)\n",
        "\n",
        "\n",
        "# Store each page as a separate document in Pinecone\n",
        "for page_num, text in texts_1:\n",
        "    store_document(f\"doc_1_page_{page_num}\", text)\n",
        "\n",
        "for page_num, text in texts_1:\n",
        "    store_document(f\"doc_2_page_{page_num}\", text)\n",
        "\n",
        "\n",
        "# Query Pinecone for a document\n",
        "query_embedding = embed_text(\"search query for the Attention paper\")\n",
        "results = index.query(vector=query_embedding, top_k=10)\n",
        "\n",
        "print(\"Results:\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTpBuf54UIdI",
        "outputId": "7329e0b6-1c29-4317-de2f-19a4ddc396a8"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "{'matches': [{'id': 'doc_1_page_3', 'score': 0.388306588, 'values': []},\n",
            "             {'id': 'doc_2_page_3', 'score': 0.388306588, 'values': []},\n",
            "             {'id': 'doc_1_page_10', 'score': 0.382295758, 'values': []},\n",
            "             {'id': 'doc_2_page_6', 'score': 0.378480464, 'values': []},\n",
            "             {'id': 'doc_1_page_6', 'score': 0.378480464, 'values': []},\n",
            "             {'id': 'doc_1_page_2', 'score': 0.359783769, 'values': []},\n",
            "             {'id': 'doc_2_page_2', 'score': 0.359783769, 'values': []},\n",
            "             {'id': 'doc_2_page_4', 'score': 0.358001769, 'values': []},\n",
            "             {'id': 'doc_1_page_4', 'score': 0.358001769, 'values': []},\n",
            "             {'id': 'doc_1_page_0', 'score': 0.34228003, 'values': []}],\n",
            " 'namespace': '',\n",
            " 'usage': {'read_units': 5}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing text strings\n",
        "\n",
        "## Function to store document in Pinecone\n",
        "#def store_document(doc_id, text):\n",
        "#    embedding = embed_text(text)\n",
        "#    index.upsert(vectors=[(doc_id, embedding)])\n",
        "\n",
        "# Store multiple strings\n",
        "store_document(\"doc_1\", \"This is the wonderful document 1.\")\n",
        "store_document(\"doc_2\", \"This is the incredible document 2.\")\n",
        "\n",
        "# Query Pinecone for multiple documents\n",
        "query_embedding_1 = embed_text(\"search query for doc 1\")\n",
        "query_embedding_2 = embed_text(\"search query for doc 2\")\n",
        "\n",
        "# Show the query embedding\n",
        "print(f\"Query embedding 1: {query_embedding_1}\")\n",
        "print(f\"Query embedding 1 dimension: {len(query_embedding_1)}\")\n",
        "print(f\"Query embedding 2: {query_embedding_2}\")\n",
        "print(f\"Query embedding 2 dimension: {len(query_embedding_2)}\")\n",
        "\n",
        "#print(index.describe_index_stats())\n"
      ],
      "metadata": {
        "id": "ILEVeTQyP_Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_1 = index.query(vector=query_embedding_1, top_k=10)\n",
        "results_2 = index.query(vector=query_embedding_2, top_k=10)\n",
        "\n",
        "print(results_2)\n",
        "print(results_1)\n"
      ],
      "metadata": {
        "id": "xL8khnPpFSAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}